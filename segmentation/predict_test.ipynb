{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import cv2\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "\n",
    "from denku import show_images\n",
    "from torch import nn\n",
    "from omegaconf import OmegaConf\n",
    "from run import preprocess_config, parse_loggers, seed_everything, DataModule, get_obj_from_str\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_config = OmegaConf.load('./output/atom/efficientnetb3_Unet_randcrop_/config.yaml')\n",
    "config = preprocess_config(main_config)\n",
    "\n",
    "seed_everything(config['common']['seed'], workers=True)\n",
    "datamodule = DataModule(config)\n",
    "\n",
    "model = get_obj_from_str(config['lightning_model'])(config)\n",
    "CHECKPOINT_PATH = './output/atom/efficientnetb3_Unet_randcrop_/best-epoch=60-iou_valid=0.47.ckpt'\n",
    "ckpt = torch.load(CHECKPOINT_PATH, map_location='cuda:0')\n",
    "\n",
    "model.model.load_state_dict(ckpt['state_dict']) \n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./dataset/test.csv')\n",
    "dem_df = test.sample(n=20, replace=True)\n",
    "\n",
    "for col, row in dem_df.iterrows():\n",
    "    mean=np.array([0, 0, 0])\n",
    "    std=np.array([1, 1, 1])\n",
    "    path_folder = '/home/raid/hdd_storage/datasets/rosatom/sam'\n",
    "    img_path = f'{path_folder}/{row[\"path_to_imgs\"]}'\n",
    "    gt_mask_path = f'{path_folder}/{row[\"path_to_masks\"]}'\n",
    "    gt_mask = cv2.imread(gt_mask_path)\n",
    "    gt_mask = cv2.resize(gt_mask, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    gt_mask = cv2.cvtColor(gt_mask, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    img = ((image.astype(np.float32) / 255.0 - mean) / std).astype(np.float32)\n",
    "#     img = image.astype(np.float32)\n",
    "\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_mask = model(img.unsqueeze(0))\n",
    "#         pred_mask = process_multimask2np(pred_mask.squeeze(0), [x for x in range(0, 14)])\n",
    "        pred_mask = pred_mask.squeeze(0).argmax(dim=0).detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    \n",
    "    image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    pred_mask = cv2.resize(pred_mask * 18, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.title('orig')\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.title('overlay')\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(pred_mask, alpha=0.5)\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.title('pred_mask')\n",
    "    plt.imshow(pred_mask)\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.title('gt_mask')\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(gt_mask, alpha=0.5)\n",
    "    plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./dataset/test.csv')\n",
    "dem_df = test.sample(n=20, replace=True)\n",
    "\n",
    "test_data = pd.DataFrame(columns=['filename','x','y','class'])\n",
    "\n",
    "for index, row in dem_df.iterrows():\n",
    "    mean=np.array([0, 0, 0])\n",
    "    std=np.array([1, 1, 1])\n",
    "    path_folder = '/home/raid/hdd_storage/datasets/rosatom/sam'\n",
    "    img_path = f'{path_folder}/{row[\"path_to_imgs\"]}'\n",
    "    gt_mask_path = f'{path_folder}/{row[\"path_to_masks\"]}'\n",
    "    gt_mask = cv2.imread(gt_mask_path)\n",
    "    gt_mask = cv2.resize(gt_mask, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    gt_mask = cv2.cvtColor(gt_mask, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    img = ((image.astype(np.float32) / 255.0 - mean) / std).astype(np.float32)\n",
    "\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_mask = model(img.unsqueeze(0))\n",
    "        pred_mask = pred_mask.squeeze(0).argmax(dim=0).detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    \n",
    "    image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    pred_mask = cv2.resize(pred_mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    u_labels = np.unique(pred_mask)\n",
    "    for u_label in u_labels:\n",
    "        if u_label == 0:\n",
    "            continue\n",
    "        mask = (pred_mask == u_label).astype(np.uint8) * 255\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0:\n",
    "                continue\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            \n",
    "            filename = row[\"path_to_imgs\"]\n",
    "            x = cX\n",
    "            y = cY\n",
    "            class_ = u_label\n",
    "            \n",
    "\n",
    "            cv2.drawContours(image, [c], -1, (0, 128, 255), 2)\n",
    "            cv2.circle(image, (cX, cY), 7, (32, 32, 255), -1)\n",
    "            cv2.putText(image, str(u_label), (cX - 5, cY - 5), cv2.FONT_HERSHEY_COMPLEX, 0.9, (128, 0, 0), 2)\n",
    "    show_images([image])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "test = pd.read_csv('./dataset/test.csv')\n",
    "\n",
    "test_data = pd.DataFrame(columns=['filename','x','y','class'])\n",
    "filename = []\n",
    "x = []\n",
    "y = []\n",
    "class_ = [] \n",
    "\n",
    "for index, row in tqdm.tqdm(test.iterrows()):\n",
    "    mean=np.array([0, 0, 0])\n",
    "    std=np.array([1, 1, 1])\n",
    "    path_folder = '/home/raid/hdd_storage/datasets/rosatom/sam'\n",
    "    img_path = f'{path_folder}/{row[\"path_to_imgs\"]}'\n",
    "    gt_mask_path = f'{path_folder}/{row[\"path_to_masks\"]}'\n",
    "    gt_mask = cv2.imread(gt_mask_path)\n",
    "    gt_mask = cv2.resize(gt_mask, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    gt_mask = cv2.cvtColor(gt_mask, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    img = ((image.astype(np.float32) / 255.0 - mean) / std).astype(np.float32)\n",
    "\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_mask = model(img.unsqueeze(0))\n",
    "        pred_mask = pred_mask.squeeze(0).argmax(dim=0).detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    \n",
    "    image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    pred_mask = cv2.resize(pred_mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    u_labels = np.unique(pred_mask)\n",
    "    for u_label in u_labels:\n",
    "        if u_label == 0:\n",
    "            continue\n",
    "        mask = (pred_mask == u_label).astype(np.uint8) * 255\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        for c in cnts:\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0:\n",
    "                continue\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            \n",
    "            filename.append(row[\"name\"])\n",
    "            x.append(cX)\n",
    "            y.append(cY)\n",
    "            class_.append(u_label)\n",
    "            \n",
    "\n",
    "            cv2.drawContours(image, [c], -1, (0, 128, 255), 2)\n",
    "            cv2.circle(image, (cX, cY), 7, (32, 32, 255), -1)\n",
    "            cv2.putText(image, str(u_label), (cX - 5, cY - 5), cv2.FONT_HERSHEY_COMPLEX, 0.9, (128, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['filename'] = filename\n",
    "test_data['x'] = x\n",
    "test_data['y'] = y\n",
    "test_data['class'] = class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('./test_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
